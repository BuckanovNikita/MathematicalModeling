{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:16:19.224014Z",
     "start_time": "2019-01-09T14:16:19.219014Z"
    }
   },
   "outputs": [],
   "source": [
    "#импорт всех необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:02:52.040132Z",
     "start_time": "2019-01-09T14:02:33.987976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/orange_small_churn_train_data.csv') # загрузка данных\n",
    "\n",
    "na_cols = [t for t in data.columns if data[t].isnull().values.all()] # обработка пустых признаков\n",
    "data = data.drop(na_cols,axis = 1)\n",
    "\n",
    "# отделение целевой переменной от данных \n",
    "labels = data['labels'] \n",
    "data = data.drop('labels', axis=1)\n",
    "\n",
    "# разбиение данных  на тренировочную и контрольную части\n",
    "data, hold_data, labels, hold_labels = train_test_split(data, labels) \n",
    "original_data = data.copy()\n",
    "original_hold_data = hold_data.copy()\n",
    "original_labels = labels.copy()\n",
    "original_hold_labels = hold_labels.copy()\n",
    "data = data.reset_index().drop(['index', 'ID'],axis=1)\n",
    "hold_data = hold_data.reset_index().drop(['index', 'ID'],axis=1)\n",
    "labels = labels.reset_index().drop(['index'],axis=1)\n",
    "labels = labels['labels']\n",
    "hold_labels = hold_labels.reset_index().drop(['index'],axis=1)\n",
    "hold_labels = hold_labels['labels']\n",
    "\n",
    "# обработка числовых признаков, заполнение пропусков в данных средним значением \n",
    "num_features = data.columns[:174]\n",
    "data[num_features] = data[num_features].fillna(data.mean())\n",
    "hold_data[num_features] = hold_data[num_features].fillna(data.mean())\n",
    "\n",
    "# обработка категориальных признаков, заполнение пропусков значением'NAN'\n",
    "cat_features = data.columns[174:]\n",
    "data[cat_features] = data[cat_features].fillna('NAN')\n",
    "hold_data[cat_features] = hold_data[cat_features].fillna('NAN')\n",
    "\n",
    "# приведение числовых признаков к 1 масштабу, One-Hot-Encoding для категориальных признаков\n",
    "# для использования в логистической регрессии\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = StandardScaler()\n",
    "col_trans = ColumnTransformer([(\"scaling:\", scaler, slice(0,174)),\n",
    "                               (\"OHE:\", ohe, slice(174,-1))],\n",
    "                               sparse_threshold=0.3, \n",
    "                               n_jobs=-1)\n",
    "data_1 = col_trans.fit_transform(data)\n",
    "hold_data_1 = col_trans.transform(hold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:02:52.895506Z",
     "start_time": "2019-01-09T14:02:52.043134Z"
    }
   },
   "outputs": [],
   "source": [
    "# приведение признаков к 1 масштабу\n",
    "for t in num_features:\n",
    "    scaler = StandardScaler()\n",
    "    data[t] = scaler.fit_transform(np.array(data[t]).reshape(-1,1))\n",
    "    hold_data[t] = scaler.transform(np.array(hold_data[t]).reshape(-1,1))\n",
    "\n",
    "# LabelEncoding для категориальных признаков \n",
    "# для использования в xgboost\n",
    "for t in cat_features:\n",
    "    scaler = LabelEncoder()\n",
    "    data[t] = scaler.fit_transform(np.array(data[t]).reshape(-1,1))\n",
    "    hold_data[t] = scaler.fit_transform(np.array(hold_data[t]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:02:52.899509Z",
     "start_time": "2019-01-09T14:02:52.896507Z"
    }
   },
   "outputs": [],
   "source": [
    "# метрики для оценки моделей\n",
    "scoring = {'f1':'f1',\n",
    "           'recall':'recall',\n",
    "           'precision': 'precision'}\n",
    "\n",
    "# метод кросс-валидации 3-разбиения, с учетом баланса классов и перемешиваннием\n",
    "cv=StratifiedKFold(3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:06:25.178522Z",
     "start_time": "2019-01-09T14:02:52.902509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=12.286093888396811, seed=None, silent=True,\n",
       "       subsample=1, tree_method='gpu_hist'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 250, 500, 1000, 2000], 'learning_rate': [0.1, 0.05, 0.02, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit='precision',\n",
       "       return_train_score='warn',\n",
       "       scoring={'f1': 'f1', 'recall': 'recall', 'precision': 'precision'},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# базовая модель градиентного бустинга\n",
    "# используется gpu ускорение, задан вес для положительного класса \n",
    "xgboost_clf = XGBClassifier(tree_method='gpu_hist', scale_pos_weight = labels.value_counts()[-1]\n",
    "                            /labels.value_counts()[1], n_jobs=-1)\n",
    "#кросс-валидация моделей\n",
    "xgb_cv = GridSearchCV(xgboost_clf, {'n_estimators' : [100, 250, 500, 1000, 2000],\n",
    "                                    'learning_rate' : [0.1, 0.05, 0.02, 0.005]},\n",
    "                      cv=cv,scoring=scoring, n_jobs=-1, refit='precision')\n",
    "xgb_cv.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:06:25.186525Z",
     "start_time": "2019-01-09T14:06:25.180523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_test_f1', 'mean_test_recall', 'mean_test_precision']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# извлечение результатов\n",
    "vals = xgb_cv.cv_results_.keys()\n",
    "vals = [t for t in vals if t[:9]=='mean_test']\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:16:39.082481Z",
     "start_time": "2019-01-09T14:16:33.611610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'n_estimators': 2000}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90      9282\n",
      "           1       0.19      0.44      0.26       718\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     10000\n",
      "   macro avg       0.57      0.65      0.58     10000\n",
      "weighted avg       0.90      0.82      0.85     10000\n",
      "\n",
      "0.8234\n"
     ]
    }
   ],
   "source": [
    "# xgboost с лучшим f1-score на котрольной выборке \n",
    "print(xgb_cv.cv_results_['params'][np.argmax(xgb_cv.cv_results_[vals[0]])])\n",
    "xgboost_clf = XGBClassifier(learning_rate = 0.05, n_estimators = 1000,\n",
    "                            tree_method='gpu_hist', scale_pos_weight = labels.value_counts()[-1]\n",
    "                            /labels.value_counts()[1], n_jobs=-1)\n",
    "xgboost_clf.fit(data, labels)\n",
    "print(classification_report(hold_labels, xgboost_clf.predict(hold_data)))\n",
    "print(accuracy_score(hold_labels, xgboost_clf.predict(hold_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:18:11.761386Z",
     "start_time": "2019-01-09T14:18:10.731164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.005, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.55      0.70      9282\n",
      "           1       0.12      0.77      0.20       718\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     10000\n",
      "   macro avg       0.54      0.66      0.45     10000\n",
      "weighted avg       0.91      0.57      0.67     10000\n",
      "\n",
      "0.5668\n"
     ]
    }
   ],
   "source": [
    "# xgboost с наибольшей  полнотой на контрольной выборке \n",
    "print(xgb_cv.cv_results_['params'][np.argmax(xgb_cv.cv_results_[vals[1]])])\n",
    "xgboost_clf = XGBClassifier(learning_rate = 0.005, n_estimators = 100,\n",
    "                            tree_method='gpu_hist', scale_pos_weight = labels.value_counts()[-1]\n",
    "                            /labels.value_counts()[1], n_jobs=-1)\n",
    "xgboost_clf.fit(data, labels)\n",
    "print(classification_report(hold_labels, xgboost_clf.predict(hold_data)))\n",
    "print(accuracy_score(hold_labels, xgboost_clf.predict(hold_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:48:36.336989Z",
     "start_time": "2019-01-09T14:48:26.000660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 2000}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.92      0.93      9282\n",
      "           1       0.20      0.26      0.23       718\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     10000\n",
      "   macro avg       0.57      0.59      0.58     10000\n",
      "weighted avg       0.89      0.87      0.88     10000\n",
      "\n",
      "0.8748\n"
     ]
    }
   ],
   "source": [
    "# xgboost с наибольшей  точностью на контрольной выборке \n",
    "print(xgb_cv.cv_results_['params'][np.argmax(xgb_cv.cv_results_[vals[2]])])\n",
    "xgboost_clf = XGBClassifier(learning_rate = 0.1, n_estimators = 2000,\n",
    "                            tree_method='gpu_hist', scale_pos_weight = labels.value_counts()[-1]\n",
    "                            /labels.value_counts()[1], n_jobs=-1)\n",
    "xgboost_clf.fit(data, labels)\n",
    "print(classification_report(hold_labels, xgboost_clf.predict(hold_data)))\n",
    "print(accuracy_score(hold_labels, xgboost_clf.predict(hold_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:24:13.627794Z",
     "start_time": "2019-01-09T14:19:40.479891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [2.0, 1.0, 0.5, 0.1, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit='precision',\n",
       "       return_train_score='warn',\n",
       "       scoring={'f1': 'f1', 'recall': 'recall', 'precision': 'precision'},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# базовая модель логистической регрессии задан вес для положительного класса \n",
    "LR = LogisticRegression(class_weight='balanced')\n",
    "# кросс-валидация\n",
    "lr_cv = GridSearchCV(LR, {'penalty' : ['l1','l2'],\n",
    "                          'C' : [2.0, 1.0, 0.5, 0.1, 0.05]},\n",
    "                     cv=cv,scoring=scoring, n_jobs=-1, refit='precision')\n",
    "lr_cv.fit(data_1, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:24:23.578566Z",
     "start_time": "2019-01-09T14:24:13.645800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'penalty': 'l2'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.66      0.78      9282\n",
      "           1       0.12      0.60      0.20       718\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10000\n",
      "   macro avg       0.54      0.63      0.49     10000\n",
      "weighted avg       0.90      0.66      0.74     10000\n",
      "\n",
      "0.6588\n"
     ]
    }
   ],
   "source": [
    "# логистическая регрессия с лучшим f1-score на котрольной выборке \n",
    "print(lr_cv.cv_results_['params'][np.argmax(lr_cv.cv_results_[vals[0]])])\n",
    "LR = LogisticRegression(class_weight='balanced', C=0.1, penalty='l1')\n",
    "LR.fit(data_1, labels)\n",
    "print(classification_report(hold_labels, LR.predict(hold_data_1)))\n",
    "print(accuracy_score(hold_labels, LR.predict(hold_data_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:24:36.714934Z",
     "start_time": "2019-01-09T14:24:23.580566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.64      0.77      9282\n",
      "           1       0.12      0.63      0.20       718\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     10000\n",
      "   macro avg       0.54      0.64      0.48     10000\n",
      "weighted avg       0.90      0.64      0.73     10000\n",
      "\n",
      "0.6407\n"
     ]
    }
   ],
   "source": [
    "# логистическая регрессия с наибольшей  полнотой на контрольной выборке \n",
    "print(lr_cv.cv_results_['params'][np.argmax(lr_cv.cv_results_[vals[1]])])\n",
    "LR = LogisticRegression(class_weight='balanced', C=0.05, penalty='l1')\n",
    "LR.fit(data_1, labels)\n",
    "print(classification_report(hold_labels, LR.predict(hold_data_1)))\n",
    "print(accuracy_score(hold_labels, LR.predict(hold_data_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:36:51.506179Z",
     "start_time": "2019-01-09T14:35:28.270723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.89      0.91      9282\n",
      "           1       0.15      0.25      0.19       718\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.54      0.57      0.55     10000\n",
      "weighted avg       0.88      0.84      0.86     10000\n",
      "\n",
      "0.8416\n"
     ]
    }
   ],
   "source": [
    "# логистическая регрессия с наибольшей  точностью на контрольной выборке \n",
    "print(lr_cv.cv_results_['params'][np.argmax(lr_cv.cv_results_[vals[2]])])\n",
    "LR = LogisticRegression(class_weight='balanced', C=1.0, penalty='l1')\n",
    "LR.fit(data_1, labels)\n",
    "print(classification_report(hold_labels, LR.predict(hold_data_1)))\n",
    "print(accuracy_score(hold_labels, LR.predict(hold_data_1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
